#!/usr/bin/env python3
"""
ä¸ºè‡ªå®šä¹‰ä»£ç é¡¹ç›®åˆ›å»º RepoEval æ ¼å¼çš„æµ‹è¯•æ•°æ®æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
    python3 create_custom_test_data.py --project_dir codesys_project/plc_hello_mixing_tank \
                                       --output_file output/repoeval/datasets/function_level_completion_2k_context_codex.test.jsonl \
                                       --repo_name plc_hello_mixing_tank
"""

import os
import json
import glob
import argparse
from pathlib import Path


def extract_code_snippets(file_path, repo_name, window_size=50):
    """
    ä»ä»£ç æ–‡ä»¶ä¸­æå–ä»£ç ç‰‡æ®µä½œä¸ºæµ‹è¯•ä»»åŠ¡
    
    Args:
        file_path: ä»£ç æ–‡ä»¶è·¯å¾„
        repo_name: ä»“åº“åç§°
        window_size: ä»£ç çª—å£å¤§å°ï¼ˆè¡Œæ•°ï¼‰
    
    Returns:
        List[Dict]: æµ‹è¯•ä»»åŠ¡åˆ—è¡¨
    """
    tasks = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return tasks
    
    if len(lines) < 10:
        return tasks
    
    # ç›¸å¯¹è·¯å¾„
    rel_path = Path(file_path).relative_to(Path(file_path).parts[0])
    fpath_tuple = list(rel_path.parts)
    
    # æ¯éš”ä¸€å®šè¡Œæ•°åˆ›å»ºä¸€ä¸ªæµ‹è¯•ä»»åŠ¡
    step = max(5, window_size // 4)
    
    for i in range(0, len(lines), step):
        if i + 5 >= len(lines):  # ç¡®ä¿è‡³å°‘æœ‰5è¡Œ
            break
        
        # ä¸Šä¸‹æ–‡ï¼šå‰é¢çš„ä»£ç 
        context_start = max(0, i - 20)
        context_end = i
        prompt_lines = lines[context_start:context_end]
        prompt = ''.join(prompt_lines)
        
        # Ground truthï¼šæ¥ä¸‹æ¥çš„å‡ è¡Œä½œä¸ºç­”æ¡ˆ
        gt_end = min(len(lines), i + 5)
        ground_truth_lines = lines[i:gt_end]
        ground_truth = ''.join(ground_truth_lines)
        
        task_id = f"{repo_name}/{'/'.join(fpath_tuple)}/{len(tasks)}"
        
        task = {
            "prompt": prompt,
            "metadata": {
                "task_id": task_id,
                "ground_truth": ground_truth,
                "fpath_tuple": fpath_tuple,
                "lineno": i,
                "context_start_lineno": context_start,
                "line_no": i
            }
        }
        tasks.append(task)
    
    return tasks


def create_test_data(project_dir, repo_name, output_file, file_extensions=None):
    """
    ä¸ºé¡¹ç›®åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶
    
    Args:
        project_dir: é¡¹ç›®ç›®å½•
        repo_name: ä»“åº“åç§°
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        file_extensions: è¦å¤„ç†çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
    """
    if file_extensions is None:
        # é»˜è®¤å¤„ç†è¿™äº›æ–‡ä»¶ç±»å‹
        file_extensions = ['.py', '.st', '.java', '.cpp', '.c', '.js', '.ts', '.go']
    
    print(f"{'='*80}")
    print(f"ğŸ“¦ ä¸ºé¡¹ç›®åˆ›å»ºæµ‹è¯•æ•°æ®")
    print(f"{'='*80}")
    print(f"é¡¹ç›®ç›®å½•: {project_dir}")
    print(f"ä»“åº“åç§°: {repo_name}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"æ–‡ä»¶ç±»å‹: {', '.join(file_extensions)}")
    print()
    
    if not os.path.exists(project_dir):
        print(f"âŒ é”™è¯¯: é¡¹ç›®ç›®å½•ä¸å­˜åœ¨ - {project_dir}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ä»£ç æ–‡ä»¶
    all_files = []
    for ext in file_extensions:
        pattern = os.path.join(project_dir, f"**/*{ext}")
        files = glob.glob(pattern, recursive=True)
        all_files.extend(files)
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(all_files)} ä¸ªä»£ç æ–‡ä»¶")
    
    # æå–æµ‹è¯•ä»»åŠ¡
    all_tasks = []
    for file_path in all_files:
        print(f"   å¤„ç†: {file_path}")
        tasks = extract_code_snippets(file_path, repo_name)
        all_tasks.extend(tasks)
        print(f"      æå–äº† {len(tasks)} ä¸ªä»»åŠ¡")
    
    print(f"\nğŸ“ æ€»å…±ç”Ÿæˆ {len(all_tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for task in all_tasks:
            f.write(json.dumps(task, ensure_ascii=False) + '\n')
    
    print(f"\nâœ… æµ‹è¯•æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    if all_tasks:
        print(f"\n{'='*80}")
        print(f"ğŸ“„ ç¬¬ä¸€ä¸ªä»»åŠ¡ç¤ºä¾‹:")
        print(f"{'='*80}")
        print(json.dumps(all_tasks[0], indent=2, ensure_ascii=False)[:500])
        print("...")
    
    return all_tasks


def main():
    parser = argparse.ArgumentParser(description='ä¸ºè‡ªå®šä¹‰é¡¹ç›®åˆ›å»º RepoEval æ ¼å¼çš„æµ‹è¯•æ•°æ®')
    parser.add_argument('--project_dir', type=str, required=True,
                       help='é¡¹ç›®æºä»£ç ç›®å½•')
    parser.add_argument('--repo_name', type=str, required=True,
                       help='ä»“åº“åç§°ï¼ˆå°†ç”¨äº task_idï¼‰')
    parser.add_argument('--output_file', type=str, required=True,
                       help='è¾“å‡º JSONL æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--extensions', type=str, nargs='+',
                       default=['.py', '.st', '.java', '.cpp', '.c', '.js', '.ts'],
                       help='è¦å¤„ç†çš„æ–‡ä»¶æ‰©å±•å')
    
    args = parser.parse_args()
    
    create_test_data(
        project_dir=args.project_dir,
        repo_name=args.repo_name,
        output_file=args.output_file,
        file_extensions=args.extensions
    )


if __name__ == "__main__":
    main()










