{"prompt": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):", "reference": "        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n", "docs": [{"text": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "class BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        if self.percentage == 1:\n            return features\n        self._store_type(features)\n        if isinstance(features, np.ndarray):\n            features = torch.from_numpy(features)\n        reduced_features = self._reduce_features(features)", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        with torch.no_grad():\n            for _ in tqdm.tqdm(range(num_coreset_samples), desc=\"Subsampling...\"):\n                select_idx = torch.argmax(approximate_coreset_anchor_distances).item()\n                coreset_indices.append(select_idx)\n                coreset_select_distance = self._compute_batchwise_differences(\n                    features, features[select_idx : select_idx + 1]  # noqa: E203\n                )\n                approximate_coreset_anchor_distances = torch.cat(\n                    [approximate_coreset_anchor_distances, coreset_select_distance],\n                    dim=-1,\n                )\n                approximate_coreset_anchor_distances = torch.min(\n                    approximate_coreset_anchor_distances, dim=1\n                ).values.reshape(-1, 1)\n\n        return np.array(coreset_indices)\n\n\nclass RandomSampler(BaseSampler):\n    def __init__(self, percentage: float):\n        super().__init__(percentage)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Randomly samples input feature collection.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        num_random_samples = int(len(features) * self.percentage)\n        subset_indices = np.random.choice(\n            len(features), num_random_samples, replace=False\n        )\n        subset_indices = np.array(subset_indices)\n        return features[subset_indices]", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        if self.percentage == 1:\n            return features\n        self._store_type(features)\n        if isinstance(features, np.ndarray):\n            features = torch.from_numpy(features)\n        reduced_features = self._reduce_features(features)\n        sample_indices = self._compute_greedy_coreset_indices(reduced_features)\n        features = features[sample_indices]\n        return self._restore_type(features)\n\n    @staticmethod\n    def _compute_batchwise_differences(\n        matrix_a: torch.Tensor, matrix_b: torch.Tensor\n    ) -> torch.Tensor:\n        \"\"\"Computes batchwise Euclidean distances using PyTorch.\"\"\"\n        a_times_a = matrix_a.unsqueeze(1).bmm(matrix_a.unsqueeze(2)).reshape(-1, 1)", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import pytest\nimport torch\nimport torch.utils.data\n\nfrom patchcore import sampler\n\n\ndef _dummy_features(feature_dimension):\n    num_samples = 5000\n    return (\n        torch.arange(num_samples).unsqueeze(1)\n        / float(num_samples)\n        * torch.ones((num_samples, feature_dimension))\n    )\n\n\ndef _dummy_constant_features(number_of_examples, feature_dimension):\n    return torch.ones([number_of_examples, feature_dimension])\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"Fails for non-GPU machine.\")\ndef test_standard_greedy_coreset_sampling():\n    feature_dimension = 2\n    init_features = _dummy_features(feature_dimension)\n\n    sampling_percentage = 0.1\n    model = sampler.GreedyCoresetSampler(\n        percentage=sampling_percentage,\n        device=torch.device(\"cpu\"),\n        dimension_to_project_features_to=feature_dimension,\n    )\n    subsampled_features = model.run(init_features)\n\n    target_num_subsampled_features = int(len(init_features) * sampling_percentage)\n    assert len(subsampled_features) == target_num_subsampled_features", "title": "amazon-science_patchcore-inspection-test-test_sampler.py"}, {"text": "        dimension_to_project_features_to=feature_dimension,\n    )\n    subsampled_features = model.run(init_features)\n\n    assert type(subsampled_features) == type(init_features)\n    assert subsampled_features.device == init_features.device\n\n    subsampled_features_numpy = model.run(init_features.numpy())\n    assert isinstance(subsampled_features_numpy, type(init_features.numpy()))\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"Fails for non-GPU machine.\")\ndef test_johnsonlindenstrauss_reduction():\n    feature_dimension = 256\n    init_features = _dummy_features(feature_dimension)\n\n    sampling_percentage = 0.1\n    dimension_to_project_features_to = 64\n\n    model = sampler.ApproximateGreedyCoresetSampler(\n        percentage=sampling_percentage,\n        device=torch.device(\"cpu\"),\n        number_of_starting_points=10,\n        dimension_to_project_features_to=dimension_to_project_features_to,\n    )\n    subsampled_features = model.run(init_features)\n\n    assert subsampled_features.shape[-1] == feature_dimension", "title": "amazon-science_patchcore-inspection-test-test_sampler.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/0", "ground_truth": "        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "sampler.py"], "context_start_lineno": 0, "lineno": 17, "function_name": "__init__"}}
{"prompt": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"", "reference": "        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n", "docs": [{"text": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import abc\nfrom typing import Union\n\nimport numpy as np\nimport torch\nimport tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "import tqdm\n\n\nclass IdentitySampler:\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        return features\n\n\nclass BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "class BaseSampler(abc.ABC):\n    def __init__(self, percentage: float):\n        if not 0 < percentage < 1:\n            raise ValueError(\"Percentage value not in (0, 1).\")\n        self.percentage = percentage\n\n    @abc.abstractmethod\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        pass\n\n    def _store_type(self, features: Union[torch.Tensor, np.ndarray]) -> None:\n        self.features_is_numpy = isinstance(features, np.ndarray)\n        if not self.features_is_numpy:\n            self.features_device = features.device\n\n    def _restore_type(self, features: torch.Tensor) -> Union[torch.Tensor, np.ndarray]:\n        if self.features_is_numpy:\n            return features.cpu().numpy()\n        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        if self.percentage == 1:\n            return features\n        self._store_type(features)\n        if isinstance(features, np.ndarray):\n            features = torch.from_numpy(features)\n        reduced_features = self._reduce_features(features)", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        return features.to(self.features_device)\n\n\nclass GreedyCoresetSampler(BaseSampler):\n    def __init__(\n        self,\n        percentage: float,\n        device: torch.device,\n        dimension_to_project_features_to=128,\n    ):\n        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        if self.percentage == 1:\n            return features\n        self._store_type(features)\n        if isinstance(features, np.ndarray):\n            features = torch.from_numpy(features)\n        reduced_features = self._reduce_features(features)\n        sample_indices = self._compute_greedy_coreset_indices(reduced_features)\n        features = features[sample_indices]\n        return self._restore_type(features)\n\n    @staticmethod\n    def _compute_batchwise_differences(\n        matrix_a: torch.Tensor, matrix_b: torch.Tensor\n    ) -> torch.Tensor:\n        \"\"\"Computes batchwise Euclidean distances using PyTorch.\"\"\"\n        a_times_a = matrix_a.unsqueeze(1).bmm(matrix_a.unsqueeze(2)).reshape(-1, 1)", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        \"\"\"Greedy Coreset sampling base class.\"\"\"\n        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n\n    def _reduce_features(self, features):\n        if features.shape[1] == self.dimension_to_project_features_to:\n            return features\n        mapper = torch.nn.Linear(\n            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        if self.percentage == 1:\n            return features\n        self._store_type(features)\n        if isinstance(features, np.ndarray):\n            features = torch.from_numpy(features)\n        reduced_features = self._reduce_features(features)\n        sample_indices = self._compute_greedy_coreset_indices(reduced_features)\n        features = features[sample_indices]\n        return self._restore_type(features)\n\n    @staticmethod\n    def _compute_batchwise_differences(\n        matrix_a: torch.Tensor, matrix_b: torch.Tensor\n    ) -> torch.Tensor:\n        \"\"\"Computes batchwise Euclidean distances using PyTorch.\"\"\"\n        a_times_a = matrix_a.unsqueeze(1).bmm(matrix_a.unsqueeze(2)).reshape(-1, 1)\n        b_times_b = matrix_b.unsqueeze(1).bmm(matrix_b.unsqueeze(2)).reshape(1, -1)\n        a_times_b = matrix_a.mm(matrix_b.T)\n\n        return (-2 * a_times_b + a_times_a + b_times_b).clamp(0, None).sqrt()\n\n    def _compute_greedy_coreset_indices(self, features: torch.Tensor) -> np.ndarray:\n        \"\"\"Runs iterative greedy coreset selection.\n\n        Args:\n            features: [NxD] input feature bank to sample.", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "        with torch.no_grad():\n            for _ in tqdm.tqdm(range(num_coreset_samples), desc=\"Subsampling...\"):\n                select_idx = torch.argmax(approximate_coreset_anchor_distances).item()\n                coreset_indices.append(select_idx)\n                coreset_select_distance = self._compute_batchwise_differences(\n                    features, features[select_idx : select_idx + 1]  # noqa: E203\n                )\n                approximate_coreset_anchor_distances = torch.cat(\n                    [approximate_coreset_anchor_distances, coreset_select_distance],\n                    dim=-1,\n                )\n                approximate_coreset_anchor_distances = torch.min(\n                    approximate_coreset_anchor_distances, dim=1\n                ).values.reshape(-1, 1)\n\n        return np.array(coreset_indices)\n\n\nclass RandomSampler(BaseSampler):\n    def __init__(self, percentage: float):\n        super().__init__(percentage)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Randomly samples input feature collection.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        num_random_samples = int(len(features) * self.percentage)\n        subset_indices = np.random.choice(\n            len(features), num_random_samples, replace=False\n        )\n        subset_indices = np.array(subset_indices)\n        return features[subset_indices]", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}, {"text": "    sampling_percentage = 0.1\n    model = sampler.GreedyCoresetSampler(\n        percentage=sampling_percentage,\n        device=torch.device(\"cpu\"),\n        dimension_to_project_features_to=feature_dimension,\n    )\n    subsampled_features = model.run(init_features)\n\n    target_num_subsampled_features = int(len(init_features) * sampling_percentage)\n    assert len(subsampled_features) == target_num_subsampled_features\n    assert (\n        len(torch.unique(subsampled_features, dim=0)) == target_num_subsampled_features\n    )\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"Fails for non-GPU machine.\")\ndef test_approximate_greedy_coreset_sampling():\n    feature_dimension = 2\n    init_features = _dummy_features(feature_dimension)\n\n    sampling_percentage = 0.1\n    model = sampler.ApproximateGreedyCoresetSampler(\n        percentage=sampling_percentage,\n        device=torch.device(\"cpu\"),\n        number_of_starting_points=10,\n        dimension_to_project_features_to=feature_dimension,\n    )\n    subsampled_features = model.run(init_features)\n\n    target_num_subsampled_features = int(len(init_features) * sampling_percentage)\n    assert len(subsampled_features) == target_num_subsampled_features\n    assert (\n        len(torch.unique(subsampled_features, dim=0)) == target_num_subsampled_features\n    )\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"Fails for non-GPU machine.\")\ndef test_coreset_sampling_on_same_samples():\n    feature_dimension = 2\n    init_features = _dummy_constant_features(5000, feature_dimension)\n\n    sampling_percentage = 0.1\n    model = sampler.ApproximateGreedyCoresetSampler(\n        percentage=sampling_percentage,\n        device=torch.device(\"cpu\"),\n        number_of_starting_points=10,\n        dimension_to_project_features_to=feature_dimension,\n    )\n    subsampled_features = model.run(init_features)\n", "title": "amazon-science_patchcore-inspection-test-test_sampler.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/1", "ground_truth": "        super().__init__(percentage)\n\n        self.device = device\n        self.dimension_to_project_features_to = dimension_to_project_features_to\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "sampler.py"], "context_start_lineno": 0, "lineno": 46, "function_name": "__init__"}}
{"prompt": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):", "reference": "            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n", "docs": [{"text": "import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "LOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/2", "ground_truth": "            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 0, "lineno": 94, "function_name": "_detach"}}
{"prompt": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"", "reference": "        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n", "docs": [{"text": "import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "LOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/3", "ground_truth": "        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 0, "lineno": 156, "function_name": "_fill_memory_bank"}}
{"prompt": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):", "reference": "            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n", "docs": [{"text": "import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "LOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/4", "ground_truth": "            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 0, "lineno": 159, "function_name": "_image_to_features"}}
{"prompt": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):", "reference": "        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n", "docs": [{"text": "import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "LOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/5", "ground_truth": "        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 0, "lineno": 178, "function_name": "predict"}}
{"prompt": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"", "reference": "        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n", "docs": [{"text": "import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "LOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(\n        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self,\n        backbone,\n        layers_to_extract_from,\n        device,\n        input_shape,\n        pretrain_embed_dimension,\n        target_embed_dimension,\n        patchsize=3,\n        patchstride=1,\n        anomaly_score_num_nn=1,\n        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\"\"\"PatchCore and PatchCore detection methods.\"\"\"\nimport logging\nimport os\nimport pickle\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport tqdm\n\nimport patchcore\nimport patchcore.backbones\nimport patchcore.common\nimport patchcore.sampler\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass PatchCore(torch.nn.Module):\n    def __init__(self, device):\n        \"\"\"PatchCore anomaly detection class.\"\"\"\n        super(PatchCore, self).__init__()\n        self.device = device\n\n    def load(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/6", "ground_truth": "        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 0, "lineno": 184, "function_name": "_predict_dataloader"}}
{"prompt": "[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n\n    def _predict(self, images):\n        \"\"\"Infer score and mask for a batch of images.\"\"\"\n        images = images.to(torch.float).to(self.device)\n        _ = self.forward_modules.eval()\n\n        batchsize = images.shape[0]\n        with torch.no_grad():\n            features, patch_shapes = self._embed(images, provide_patch_shapes=True)\n            features = np.asarray(features)\n\n            patch_scores = image_scores = self.anomaly_scorer.predict([features])[0]\n            image_scores = self.patch_maker.unpatch_scores(\n                image_scores, batchsize=batchsize\n            )\n            image_scores = image_scores.reshape(*image_scores.shape[:2], -1)\n            image_scores = self.patch_maker.score(image_scores)\n\n            patch_scores = self.patch_maker.unpatch_scores(\n                patch_scores, batchsize=batchsize\n            )\n            scales = patch_shapes[0]\n            patch_scores = patch_scores.reshape(batchsize, scales[0], scales[1])\n\n            masks = self.anomaly_segmentor.convert_to_segmentation(patch_scores)\n\n        return [score for score in image_scores], [mask for mask in masks]\n\n    @staticmethod\n    def _params_file(filepath, prepend=\"\"):\n        return os.path.join(filepath, prepend + \"patchcore_params.pkl\")\n\n    def save_to_path(self, save_path: str, prepend: str = \"\") -> None:", "reference": "        LOGGER.info(\"Saving PatchCore data.\")\n        self.anomaly_scorer.save(\n            save_path, save_features_separately=False, prepend=prepend\n        )\n        patchcore_params = {\n            \"backbone.name\": self.backbone.name,\n            \"layers_to_extract_from\": self.layers_to_extract_from,\n            \"input_shape\": self.input_shape,\n            \"pretrain_embed_dimension\": self.forward_modules[\n                \"preprocessing\"\n            ].output_dim,\n            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n", "docs": [{"text": "            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        featuresampler=patchcore.sampler.IdentitySampler(),\n        nn_method=patchcore.common.FaissNN(False, 4),\n        **kwargs,\n    ):\n        self.backbone = backbone.to(device)\n        self.layers_to_extract_from = layers_to_extract_from\n        self.input_shape = input_shape\n\n        self.device = device\n        self.patch_maker = PatchMaker(patchsize, stride=patchstride)\n\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/7", "ground_truth": "        LOGGER.info(\"Saving PatchCore data.\")\n        self.anomaly_scorer.save(\n            save_path, save_features_separately=False, prepend=prepend\n        )\n        patchcore_params = {\n            \"backbone.name\": self.backbone.name,\n            \"layers_to_extract_from\": self.layers_to_extract_from,\n            \"input_shape\": self.input_shape,\n            \"pretrain_embed_dimension\": self.forward_modules[\n                \"preprocessing\"\n            ].output_dim,\n            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 57, "lineno": 234, "function_name": "save_to_path"}}
{"prompt": "features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n\n    def _predict(self, images):\n        \"\"\"Infer score and mask for a batch of images.\"\"\"\n        images = images.to(torch.float).to(self.device)\n        _ = self.forward_modules.eval()\n\n        batchsize = images.shape[0]\n        with torch.no_grad():\n            features, patch_shapes = self._embed(images, provide_patch_shapes=True)\n            features = np.asarray(features)\n\n            patch_scores = image_scores = self.anomaly_scorer.predict([features])[0]\n            image_scores = self.patch_maker.unpatch_scores(\n                image_scores, batchsize=batchsize\n            )\n            image_scores = image_scores.reshape(*image_scores.shape[:2], -1)\n            image_scores = self.patch_maker.score(image_scores)\n\n            patch_scores = self.patch_maker.unpatch_scores(\n                patch_scores, batchsize=batchsize\n            )\n            scales = patch_shapes[0]\n            patch_scores = patch_scores.reshape(batchsize, scales[0], scales[1])\n\n            masks = self.anomaly_segmentor.convert_to_segmentation(patch_scores)\n\n        return [score for score in image_scores], [mask for mask in masks]\n\n    @staticmethod\n    def _params_file(filepath, prepend=\"\"):\n        return os.path.join(filepath, prepend + \"patchcore_params.pkl\")\n\n    def save_to_path(self, save_path: str, prepend: str = \"\") -> None:\n        LOGGER.info(\"Saving PatchCore data.\")\n        self.anomaly_scorer.save(\n            save_path, save_features_separately=False, prepend=prepend\n        )\n        patchcore_params = {\n            \"backbone.name\": self.backbone.name,\n            \"layers_to_extract_from\": self.layers_to_extract_from,\n            \"input_shape\": self.input_shape,\n            \"pretrain_embed_dimension\": self.forward_modules[\n                \"preprocessing\"\n            ].output_dim,\n            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"", "reference": "        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []\n        for s in features.shape[-2:]:\n            n_patches = (\n                s + 2 * padding - 1 * (self.patchsize - 1) - 1\n            ) / self.stride + 1\n            number_of_total_patches.append(int(n_patches))\n        unfolded_features = unfolded_features.reshape(\n            *features.shape[:2], self.patchsize, self.patchsize, -1\n        )\n        unfolded_features = unfolded_features.permute(0, 4, 1, 2, 3)\n\n        if return_spatial_info:\n            return unfolded_features, number_of_total_patches\n        return unfolded_features\n", "docs": [{"text": "            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n\n            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            features.shape[1], self.dimension_to_project_features_to, bias=False\n        )\n        _ = mapper.to(self.device)\n        features = features.to(self.device)\n        return mapper(features)\n\n    def run(\n        self, features: Union[torch.Tensor, np.ndarray]\n    ) -> Union[torch.Tensor, np.ndarray]:\n        \"\"\"Subsamples features using Greedy Coreset.\n\n        Args:\n            features: [N x D]\n        \"\"\"\n        if self.percentage == 1:\n            return features\n        self._store_type(features)\n        if isinstance(features, np.ndarray):\n            features = torch.from_numpy(features)\n        reduced_features = self._reduce_features(features)\n        sample_indices = self._compute_greedy_coreset_indices(reduced_features)\n        features = features[sample_indices]\n        return self._restore_type(features)\n\n    @staticmethod\n    def _compute_batchwise_differences(\n        matrix_a: torch.Tensor, matrix_b: torch.Tensor\n    ) -> torch.Tensor:\n        \"\"\"Computes batchwise Euclidean distances using PyTorch.\"\"\"\n        a_times_a = matrix_a.unsqueeze(1).bmm(matrix_a.unsqueeze(2)).reshape(-1, 1)\n        b_times_b = matrix_b.unsqueeze(1).bmm(matrix_b.unsqueeze(2)).reshape(1, -1)\n        a_times_b = matrix_a.mm(matrix_b.T)\n\n        return (-2 * a_times_b + a_times_a + b_times_b).clamp(0, None).sqrt()\n\n    def _compute_greedy_coreset_indices(self, features: torch.Tensor) -> np.ndarray:\n        \"\"\"Runs iterative greedy coreset selection.\n\n        Args:\n            features: [NxD] input feature bank to sample.\n        \"\"\"\n        distance_matrix = self._compute_batchwise_differences(features, features)\n        coreset_anchor_distances = torch.norm(distance_matrix, dim=1)\n\n        coreset_indices = []\n        num_coreset_samples = int(len(features) * self.percentage)\n\n        for _ in range(num_coreset_samples):\n            select_idx = torch.argmax(coreset_anchor_distances).item()\n            coreset_indices.append(select_idx)", "title": "amazon-science_patchcore-inspection-src-patchcore-sampler.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/8", "ground_truth": "        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []\n        for s in features.shape[-2:]:\n            n_patches = (\n                s + 2 * padding - 1 * (self.patchsize - 1) - 1\n            ) / self.stride + 1\n            number_of_total_patches.append(int(n_patches))\n        unfolded_features = unfolded_features.reshape(\n            *features.shape[:2], self.patchsize, self.patchsize, -1\n        )\n        unfolded_features = unfolded_features.permute(0, 4, 1, 2, 3)\n\n        if return_spatial_info:\n            return unfolded_features, number_of_total_patches\n        return unfolded_features\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 120, "lineno": 289, "function_name": "patchify"}}
{"prompt": "[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n\n    def _predict(self, images):\n        \"\"\"Infer score and mask for a batch of images.\"\"\"\n        images = images.to(torch.float).to(self.device)\n        _ = self.forward_modules.eval()\n\n        batchsize = images.shape[0]\n        with torch.no_grad():\n            features, patch_shapes = self._embed(images, provide_patch_shapes=True)\n            features = np.asarray(features)\n\n            patch_scores = image_scores = self.anomaly_scorer.predict([features])[0]\n            image_scores = self.patch_maker.unpatch_scores(\n                image_scores, batchsize=batchsize\n            )\n            image_scores = image_scores.reshape(*image_scores.shape[:2], -1)\n            image_scores = self.patch_maker.score(image_scores)\n\n            patch_scores = self.patch_maker.unpatch_scores(\n                patch_scores, batchsize=batchsize\n            )\n            scales = patch_shapes[0]\n            patch_scores = patch_scores.reshape(batchsize, scales[0], scales[1])\n\n            masks = self.anomaly_segmentor.convert_to_segmentation(patch_scores)\n\n        return [score for score in image_scores], [mask for mask in masks]\n\n    @staticmethod\n    def _params_file(filepath, prepend=\"\"):\n        return os.path.join(filepath, prepend + \"patchcore_params.pkl\")\n\n    def save_to_path(self, save_path: str, prepend: str = \"\") -> None:\n        LOGGER.info(\"Saving PatchCore data.\")\n        self.anomaly_scorer.save(\n            save_path, save_features_separately=False, prepend=prepend\n        )\n        patchcore_params = {\n            \"backbone.name\": self.backbone.name,\n            \"layers_to_extract_from\": self.layers_to_extract_from,\n            \"input_shape\": self.input_shape,\n            \"pretrain_embed_dimension\": self.forward_modules[\n                \"preprocessing\"\n            ].output_dim,\n            \"target_embed_dimension\": self.forward_modules[\n                \"preadapt_aggregator\"\n            ].target_dim,\n            \"patchsize\": self.patch_maker.patchsize,\n            \"patchstride\": self.patch_maker.stride,\n            \"anomaly_scorer_num_nn\": self.anomaly_scorer.n_nearest_neighbours,\n        }\n        with open(self._params_file(save_path, prepend), \"wb\") as save_file:\n            pickle.dump(patchcore_params, save_file, pickle.HIGHEST_PROTOCOL)\n\n    def load_from_path(\n        self,\n        load_path: str,\n        device: torch.device,\n        nn_method: patchcore.common.FaissNN(False, 4),\n        prepend: str = \"\",\n    ) -> None:\n        LOGGER.info(\"Loading and initializing PatchCore.\")\n        with open(self._params_file(load_path, prepend), \"rb\") as load_file:\n            patchcore_params = pickle.load(load_file)\n        patchcore_params[\"backbone\"] = patchcore.backbones.load(\n            patchcore_params[\"backbone.name\"]\n        )\n        patchcore_params[\"backbone\"].name = patchcore_params[\"backbone.name\"]\n        del patchcore_params[\"backbone.name\"]\n        self.load(**patchcore_params, device=device, nn_method=nn_method)\n\n        self.anomaly_scorer.load(load_path, prepend)\n\n\n# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []\n        for s in features.shape[-2:]:\n            n_patches = (\n                s + 2 * padding - 1 * (self.patchsize - 1) - 1\n            ) / self.stride + 1\n            number_of_total_patches.append(int(n_patches))\n        unfolded_features = unfolded_features.reshape(\n            *features.shape[:2], self.patchsize, self.patchsize, -1\n        )\n        unfolded_features = unfolded_features.permute(0, 4, 1, 2, 3)\n\n        if return_spatial_info:\n            return unfolded_features, number_of_total_patches\n        return unfolded_features\n\n    def unpatch_scores(self, x, batchsize):\n        return x.reshape(batchsize, -1, *x.shape[1:])\n\n    def score(self, x):", "reference": "        was_numpy = False\n        if isinstance(x, np.ndarray):\n            was_numpy = True\n            x = torch.from_numpy(x)\n        while x.ndim > 1:\n            x = torch.max(x, dim=-1).values\n        if was_numpy:\n            return x.numpy()\n        return x\n", "docs": [{"text": "\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n\n    def _predict(self, images):\n        \"\"\"Infer score and mask for a batch of images.\"\"\"\n        images = images.to(torch.float).to(self.device)", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(\n            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            input_data, desc=\"Computing support features...\", position=1, leave=False\n        ) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                features.append(_image_to_features(image))\n\n        features = np.concatenate(features, axis=0)\n        features = self.featuresampler.run(features)\n\n        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n\n    def _predict(self, images):\n        \"\"\"Infer score and mask for a batch of images.\"\"\"\n        images = images.to(torch.float).to(self.device)\n        _ = self.forward_modules.eval()\n\n        batchsize = images.shape[0]\n        with torch.no_grad():\n            features, patch_shapes = self._embed(images, provide_patch_shapes=True)\n            features = np.asarray(features)\n\n            patch_scores = image_scores = self.anomaly_scorer.predict([features])[0]\n            image_scores = self.patch_maker.unpatch_scores(\n                image_scores, batchsize=batchsize", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [\n            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n        ]\n        patch_shapes = [x[1] for x in features]\n        features = [x[0] for x in features]\n        ref_num_patches = patch_shapes[0]\n\n        for i in range(1, len(features)):\n            _features = features[i]\n            patch_dims = patch_shapes[i]\n", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "            # TODO(pgehler): Add comments\n            _features = _features.reshape(\n                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n            )\n            _features = _features.permute(0, -3, -2, -1, 1, 2)\n            perm_base_shape = _features.shape\n            _features = _features.reshape(-1, *_features.shape[-2:])\n            _features = F.interpolate(\n                _features.unsqueeze(1),\n                size=(ref_num_patches[0], ref_num_patches[1]),\n                mode=\"bilinear\",\n                align_corners=False,\n            )\n            _features = _features.squeeze(1)\n            _features = _features.reshape(\n                *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n            )\n            _features = _features.permute(0, -2, -1, 1, 2, 3)\n            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n            features[i] = _features\n        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n\n        # As different feature backbones & patching provide differently\n        # sized features, these are brought into the correct form here.\n        features = self.forward_modules[\"preprocessing\"](features)\n        features = self.forward_modules[\"preadapt_aggregator\"](features)\n\n        if provide_patch_shapes:\n            return _detach(features), patch_shapes\n        return _detach(features)\n\n    def fit(self, training_data):\n        \"\"\"PatchCore training.\n\n        This function computes the embeddings of the training data and fills the\n        memory bank of SPADE.\n        \"\"\"\n        self._fill_memory_bank(training_data)\n\n    def _fill_memory_bank(self, input_data):\n        \"\"\"Computes and sets the support features for SPADE.\"\"\"\n        _ = self.forward_modules.eval()\n\n        def _image_to_features(input_image):\n            with torch.no_grad():\n                input_image = input_image.to(torch.float).to(self.device)\n                return self._embed(input_image)\n\n        features = []\n        with tqdm.tqdm(", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self.anomaly_scorer.fit(detection_features=[features])\n\n    def predict(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            return self._predict_dataloader(data)\n        return self._predict(data)\n\n    def _predict_dataloader(self, dataloader):\n        \"\"\"This function provides anomaly scores/maps for full dataloaders.\"\"\"\n        _ = self.forward_modules.eval()\n\n        scores = []\n        masks = []\n        labels_gt = []\n        masks_gt = []\n        with tqdm.tqdm(dataloader, desc=\"Inferring...\", leave=False) as data_iterator:\n            for image in data_iterator:\n                if isinstance(image, dict):\n                    labels_gt.extend(image[\"is_anomaly\"].numpy().tolist())\n                    masks_gt.extend(image[\"mask\"].numpy().tolist())\n                    image = image[\"image\"]\n                _scores, _masks = self._predict(image)\n                for score, mask in zip(_scores, _masks):\n                    scores.append(score)\n                    masks.append(mask)\n        return scores, masks, labels_gt, masks_gt\n\n    def _predict(self, images):\n        \"\"\"Infer score and mask for a batch of images.\"\"\"\n        images = images.to(torch.float).to(self.device)\n        _ = self.forward_modules.eval()\n\n        batchsize = images.shape[0]\n        with torch.no_grad():\n            features, patch_shapes = self._embed(images, provide_patch_shapes=True)\n            features = np.asarray(features)\n\n            patch_scores = image_scores = self.anomaly_scorer.predict([features])[0]\n            image_scores = self.patch_maker.unpatch_scores(\n                image_scores, batchsize=batchsize\n            )\n            image_scores = image_scores.reshape(*image_scores.shape[:2], -1)\n            image_scores = self.patch_maker.score(image_scores)\n\n            patch_scores = self.patch_maker.unpatch_scores(\n                patch_scores, batchsize=batchsize\n            )\n            scales = patch_shapes[0]\n            patch_scores = patch_scores.reshape(batchsize, scales[0], scales[1])\n", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "\n        self.forward_modules = torch.nn.ModuleDict({})\n\n        feature_aggregator = patchcore.common.NetworkFeatureAggregator(\n            self.backbone, self.layers_to_extract_from, self.device\n        )\n        feature_dimensions = feature_aggregator.feature_dimensions(input_shape)\n        self.forward_modules[\"feature_aggregator\"] = feature_aggregator\n\n        preprocessing = patchcore.common.Preprocessing(\n            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/9", "ground_truth": "        was_numpy = False\n        if isinstance(x, np.ndarray):\n            was_numpy = True\n            x = torch.from_numpy(x)\n        while x.ndim > 1:\n            x = torch.max(x, dim=-1).values\n        if was_numpy:\n            return x.numpy()\n        return x\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "patchcore.py"], "context_start_lineno": 140, "lineno": 313, "function_name": "score"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"", "reference": "        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "docs": [{"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/10", "ground_truth": "        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 21, "function_name": "__init__"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):", "reference": "        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n", "docs": [{"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/11", "ground_truth": "        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 29, "function_name": "_index_to_gpu"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):", "reference": "        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n", "docs": [{"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/12", "ground_truth": "        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 38, "function_name": "_index_to_cpu"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):", "reference": "        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n", "docs": [{"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/13", "ground_truth": "        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 43, "function_name": "_create_index"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"", "reference": "        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/14", "ground_truth": "        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 56, "function_name": "fit"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"", "reference": "        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/15", "ground_truth": "        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 78, "function_name": "run"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):", "reference": "        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/16", "ground_truth": "        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 94, "function_name": "reset_index"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):", "reference": "        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/17", "ground_truth": "        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 109, "function_name": "_create_index"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC", "reference": "        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/18", "ground_truth": "        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 132, "function_name": "_reduce"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):", "reference": "        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/19", "ground_truth": "        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 146, "function_name": "__init__"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):", "reference": "        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/20", "ground_truth": "        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 156, "function_name": "forward"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim", "reference": "        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/21", "ground_truth": "        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 180, "function_name": "forward"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):", "reference": "        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/22", "ground_truth": "        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 187, "function_name": "__init__"}}
{"prompt": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):", "reference": "        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n", "docs": [{"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "import copy\nimport os\nimport pickle\nfrom typing import List\nfrom typing import Union\n\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/23", "ground_truth": "        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 0, "lineno": 193, "function_name": "convert_to_segmentation"}}
{"prompt": "features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):", "reference": "        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n", "docs": [{"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    nn_search.fit(index)\n    distances_after_set_index, nn_indices_after_set_index = nn_search.run(2, query)\n\n    assert np.all(distances_before_set_index == distances_after_set_index)\n    assert np.all(nn_indices_before_set_index == nn_indices_after_set_index)\n\n\ndef test_approximate_faiss():\n    query = np.ones([768, 128], dtype=np.float32)\n    index = 2 * query\n\n    nn_search = common.ApproximateFaissNN()\n\n    distances_before_set_index, nn_indices_before_set_index = nn_search.run(\n        2, query, index\n    )\n    nn_search.fit(index)\n    distances_after_set_index, nn_indices_after_set_index = nn_search.run(2, query)\n\n    assert np.all(distances_before_set_index == distances_after_set_index)\n    assert np.all(nn_indices_before_set_index == nn_indices_after_set_index)\n\n\ndef test_search_without_index_raises_exception():\n    features = np.arange(3 * 6, dtype=np.float32).reshape(3, 6)\n    nn_search = common.FaissNN(on_gpu=False, num_workers=4)\n    with pytest.raises(AttributeError):\n        nn_search.run(2, features)\n    assert nn_search.run(2, features, features) is not None\n\n\ndef test_read_write_index(tmpdir):\n    index_filename = (tmpdir / \"index\").strpath\n    nn_model = common.FaissNN()\n    features = np.arange(3 * 6, dtype=np.float32).reshape(3, 6)\n    nn_model.fit(features)\n    nn_model.save(index_filename)\n\n    loaded_nn_model = common.FaissNN()\n    loaded_nn_model.load(index_filename)\n\n    query_features = np.arange(10 * 6, dtype=np.float32).reshape(10, 6)\n    assert loaded_nn_model.run(2, query_features) is not None\n    assert np.all(\n        loaded_nn_model.run(2, query_features)[0] == nn_model.run(2, query_features)[0]\n    )\n    assert np.all(\n        loaded_nn_model.run(2, query_features)[1] == nn_model.run(2, query_features)[1]\n    )\n", "title": "amazon-science_patchcore-inspection-test-test_common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/24", "ground_truth": "        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 58, "lineno": 259, "function_name": "forward"}}
{"prompt": "]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"", "reference": "        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n", "docs": [{"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\n        Searches for nearest neighbours of test images in all\n        support training images.\n\n        Args:\n             detection_query_features: [dict of np.arrays] List of np.arrays\n                 corresponding to the test features generated by\n                 some backbone network.\n        \"\"\"\n        query_features = self.feature_merger.merge(\n            query_features,\n        )\n        query_distances, query_nns = self.imagelevel_nn(query_features)\n        anomaly_scores = np.mean(query_distances, axis=-1)\n        return anomaly_scores, query_distances, query_nns\n\n    @staticmethod\n    def _detection_file(folder, prepend=\"\"):\n        return os.path.join(folder, prepend + \"nnscorer_features.pkl\")\n\n    @staticmethod\n    def _index_file(folder, prepend=\"\"):\n        return os.path.join(folder, prepend + \"nnscorer_search_index.faiss\")\n\n    @staticmethod\n    def _save(filename, features):\n        if features is None:\n            return\n        with open(filename, \"wb\") as save_file:\n            pickle.dump(features, save_file, pickle.HIGHEST_PROTOCOL)\n\n    @staticmethod\n    def _load(filename: str):\n        with open(filename, \"rb\") as load_file:\n            return pickle.load(load_file)\n\n    def save(\n        self,\n        save_folder: str,\n        save_features_separately: bool = False,\n        prepend: str = \"\",\n    ) -> None:\n        self.nn_method.save(self._index_file(save_folder, prepend))\n        if save_features_separately:\n            self._save(\n                self._detection_file(save_folder, prepend), self.detection_features\n            )\n\n    def save_and_reset(self, save_folder: str) -> None:\n        self.save(save_folder)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/25", "ground_truth": "        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 70, "lineno": 271, "function_name": "feature_dimensions"}}
{"prompt": "index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):", "reference": "        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n", "docs": [{"text": "        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/26", "ground_truth": "        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 82, "lineno": 278, "function_name": "__init__"}}
{"prompt": ", filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):", "reference": "        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n", "docs": [{"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\nimport faiss\nimport numpy as np\nimport scipy.ndimage as ndimage\nimport torch\nimport torch.nn.functional as F\n\n\nclass FaissNN(object):\n    def __init__(self, on_gpu: bool = False, num_workers: int = 4) -> None:\n        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"FAISS Nearest neighbourhood search.\n\n        Args:\n            on_gpu: If set true, nearest neighbour searches are done on GPU.\n            num_workers: Number of workers to use with FAISS for similarity search.\n        \"\"\"\n        faiss.omp_set_num_threads(num_workers)\n        self.on_gpu = on_gpu\n        self.search_index = None\n\n    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/27", "ground_truth": "        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 87, "lineno": 285, "function_name": "__call__"}}
{"prompt": " True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):\n        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n\n\nclass LastLayerToExtractReachedException(Exception):\n    pass\n\n\nclass NearestNeighbourScorer(object):\n    def __init__(self, n_nearest_neighbours: int, nn_method=FaissNN(False, 4)) -> None:\n        \"\"\"\n        Neearest-Neighbourhood Anomaly Scorer class.\n\n        Args:\n            n_nearest_neighbours: [int] Number of nearest neighbours used to\n                determine anomalous pixels.\n            nn_method: Nearest neighbour search method.\n        \"\"\"", "reference": "        self.feature_merger = ConcatMerger()\n\n        self.n_nearest_neighbours = n_nearest_neighbours\n        self.nn_method = nn_method\n\n        self.imagelevel_nn = lambda query: self.nn_method.run(\n            n_nearest_neighbours, query\n        )\n        self.pixelwise_nn = lambda query, index: self.nn_method.run(1, query, index)\n", "docs": [{"text": "        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:\n            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def _gpu_cloner_options(self):\n        return faiss.GpuClonerOptions()\n\n    def _index_to_gpu(self, index):\n        if self.on_gpu:\n            # For the non-gpu faiss python package, there is no GpuClonerOptions\n            # so we can not make a default in the function header.\n            return faiss.index_cpu_to_gpu(\n                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()\n            )\n        return index\n\n    def _index_to_cpu(self, index):\n        if self.on_gpu:\n            return faiss.index_gpu_to_cpu(index)\n        return index\n\n    def _create_index(self, dimension):\n        if self.on_gpu:\n            return faiss.GpuIndexFlatL2(\n                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()\n            )\n        return faiss.IndexFlatL2(dimension)\n\n    def fit(self, features: np.ndarray) -> None:\n        \"\"\"\n        Adds features to the FAISS search index.\n\n        Args:\n            features: Array of size NxD.\n        \"\"\"\n        if self.search_index:\n            self.reset_index()\n        self.search_index = self._create_index(features.shape[-1])\n        self._train(self.search_index, features)\n        self.search_index.add(features)\n\n    def _train(self, _index, _features):\n        pass\n\n    def run(\n        self,\n        n_nearest_neighbours,\n        query_features: np.ndarray,\n        index_features: np.ndarray = None,\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Returns distances and indices of nearest neighbour search.\n\n        Args:", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            query_features: Features to retrieve.\n            index_features: [optional] Index features to search in.\n        \"\"\"\n        if index_features is None:\n            return self.search_index.search(query_features, n_nearest_neighbours)\n\n        # Build a search index just for this search.\n        search_index = self._create_index(index_features.shape[-1])\n        self._train(search_index, index_features)\n        search_index.add(index_features)\n        return search_index.search(query_features, n_nearest_neighbours)\n\n    def save(self, filename: str) -> None:\n        faiss.write_index(self._index_to_cpu(self.search_index), filename)\n\n    def load(self, filename: str) -> None:\n        self.search_index = self._index_to_gpu(faiss.read_index(filename))\n\n    def reset_index(self):\n        if self.search_index:\n            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/28", "ground_truth": "        self.feature_merger = ConcatMerger()\n\n        self.n_nearest_neighbours = n_nearest_neighbours\n        self.nn_method = nn_method\n\n        self.imagelevel_nn = lambda query: self.nn_method.run(\n            n_nearest_neighbours, query\n        )\n        self.pixelwise_nn = lambda query, index: self.nn_method.run(1, query, index)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 105, "lineno": 305, "function_name": "__init__"}}
{"prompt": "        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):\n        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n\n\nclass LastLayerToExtractReachedException(Exception):\n    pass\n\n\nclass NearestNeighbourScorer(object):\n    def __init__(self, n_nearest_neighbours: int, nn_method=FaissNN(False, 4)) -> None:\n        \"\"\"\n        Neearest-Neighbourhood Anomaly Scorer class.\n\n        Args:\n            n_nearest_neighbours: [int] Number of nearest neighbours used to\n                determine anomalous pixels.\n            nn_method: Nearest neighbour search method.\n        \"\"\"\n        self.feature_merger = ConcatMerger()\n\n        self.n_nearest_neighbours = n_nearest_neighbours\n        self.nn_method = nn_method\n\n        self.imagelevel_nn = lambda query: self.nn_method.run(\n            n_nearest_neighbours, query\n        )\n        self.pixelwise_nn = lambda query, index: self.nn_method.run(1, query, index)\n\n    def fit(self, detection_features: List[np.ndarray]) -> None:\n        \"\"\"Calls the fit function of the nearest neighbour method.\n\n        Args:\n            detection_features: [list of np.arrays]\n                [[bs x d_i] for i in n] Contains a list of\n                np.arrays for all training images corresponding to respective\n                features VECTORS (or maps, but will be resized) produced by\n                some backbone network which should be used for image-level\n                anomaly detection.\n        \"\"\"", "reference": "        self.detection_features = self.feature_merger.merge(\n            detection_features,\n        )\n        self.nn_method.fit(self.detection_features)\n", "docs": [{"text": "\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "# Image handling classes.\nclass PatchMaker:\n    def __init__(self, patchsize, stride=None):\n        self.patchsize = patchsize\n        self.stride = stride\n\n    def patchify(self, features, return_spatial_info=False):\n        \"\"\"Convert a tensor into a tensor of respective patches.\n        Args:\n            x: [torch.Tensor, bs x c x w x h]\n        Returns:\n            x: [torch.Tensor, bs * w//stride * h//stride, c, patchsize,\n            patchsize]\n        \"\"\"\n        padding = int((self.patchsize - 1) / 2)\n        unfolder = torch.nn.Unfold(\n            kernel_size=self.patchsize, stride=self.stride, padding=padding, dilation=1\n        )\n        unfolded_features = unfolder(features)\n        number_of_total_patches = []\n        for s in features.shape[-2:]:\n            n_patches = (\n                s + 2 * padding - 1 * (self.patchsize - 1) - 1\n            ) / self.stride + 1\n            number_of_total_patches.append(int(n_patches))\n        unfolded_features = unfolded_features.reshape(\n            *features.shape[:2], self.patchsize, self.patchsize, -1\n        )\n        unfolded_features = unfolded_features.permute(0, 4, 1, 2, 3)\n\n        if return_spatial_info:\n            return unfolded_features, number_of_total_patches\n        return unfolded_features\n\n    def unpatch_scores(self, x, batchsize):\n        return x.reshape(batchsize, -1, *x.shape[1:])\n\n    def score(self, x):\n        was_numpy = False\n        if isinstance(x, np.ndarray):\n            was_numpy = True\n            x = torch.from_numpy(x)\n        while x.ndim > 1:\n            x = torch.max(x, dim=-1).values\n        if was_numpy:\n            return x.numpy()\n        return x", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}, {"text": "        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    merger = common.AverageMerger()\n    output_features = merger.merge(input_features)\n    assert np.all(output_features.shape == (2, 7))\n\n\ndef test_average_merger_output():\n    input_features = [np.ones([2, 3, 4, 5])]\n\n    merger = common.AverageMerger()\n    output_features = merger.merge(input_features)\n    assert np.all(output_features == 1.0)\n\n\ndef test_concat_merger_shape():\n    input_features = []\n    input_features.append(np.arange(2 * 3 * 4 * 5).reshape([2, 3, 4, 5]))\n    input_features.append(2 * np.arange(2 * 3 * 4 * 5).reshape([2, 4, 3, 5]))\n\n    merger = common.ConcatMerger()\n    output_features = merger.merge([input_features[0]])\n    assert np.all(output_features.shape == (2, 3 * 4 * 5))\n\n    merger = common.ConcatMerger()\n    output_features = merger.merge(input_features)\n    assert np.all(output_features.shape == (2, 3 * 4 * 5 + 4 * 3 * 5))\n\n\ndef test_concat_merger_output():\n    input_features = []\n    input_features.append(np.ones([2, 3, 4, 5]))\n    input_features.append(2 * np.ones([2, 3, 4, 5]))\n\n    merger = common.ConcatMerger()\n    output_features = merger.merge([input_features[0]])\n    assert np.all(output_features == 1.0)\n\n    merger = common.ConcatMerger()\n    output_features = merger.merge(input_features)\n    assert np.all(output_features[:, : 3 * 4 * 5] == 1.0)\n    assert np.all(output_features[:, 3 * 4 * 5 :] == 2.0)", "title": "amazon-science_patchcore-inspection-test-test_common.py"}, {"text": "            self.search_index.reset()\n            self.search_index = None\n\n\nclass ApproximateFaissNN(FaissNN):\n    def _train(self, index, features):\n        index.train(features)\n\n    def _gpu_cloner_options(self):\n        cloner = faiss.GpuClonerOptions()\n        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/29", "ground_truth": "        self.detection_features = self.feature_merger.merge(\n            detection_features,\n        )\n        self.nn_method.fit(self.detection_features)\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 134, "lineno": 326, "function_name": "fit"}}
{"prompt": " = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):\n        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n\n\nclass LastLayerToExtractReachedException(Exception):\n    pass\n\n\nclass NearestNeighbourScorer(object):\n    def __init__(self, n_nearest_neighbours: int, nn_method=FaissNN(False, 4)) -> None:\n        \"\"\"\n        Neearest-Neighbourhood Anomaly Scorer class.\n\n        Args:\n            n_nearest_neighbours: [int] Number of nearest neighbours used to\n                determine anomalous pixels.\n            nn_method: Nearest neighbour search method.\n        \"\"\"\n        self.feature_merger = ConcatMerger()\n\n        self.n_nearest_neighbours = n_nearest_neighbours\n        self.nn_method = nn_method\n\n        self.imagelevel_nn = lambda query: self.nn_method.run(\n            n_nearest_neighbours, query\n        )\n        self.pixelwise_nn = lambda query, index: self.nn_method.run(1, query, index)\n\n    def fit(self, detection_features: List[np.ndarray]) -> None:\n        \"\"\"Calls the fit function of the nearest neighbour method.\n\n        Args:\n            detection_features: [list of np.arrays]\n                [[bs x d_i] for i in n] Contains a list of\n                np.arrays for all training images corresponding to respective\n                features VECTORS (or maps, but will be resized) produced by\n                some backbone network which should be used for image-level\n                anomaly detection.\n        \"\"\"\n        self.detection_features = self.feature_merger.merge(\n            detection_features,\n        )\n        self.nn_method.fit(self.detection_features)\n\n    def predict(\n        self, query_features: List[np.ndarray]\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Predicts anomaly score.\n\n        Searches for nearest neighbours of test images in all\n        support training images.\n\n        Args:\n             detection_query_features: [dict of np.arrays] List of np.arrays\n                 corresponding to the test features generated by\n                 some backbone network.\n        \"\"\"", "reference": "        query_features = self.feature_merger.merge(\n            query_features,\n        )\n        query_distances, query_nns = self.imagelevel_nn(query_features)\n        anomaly_scores = np.mean(query_distances, axis=-1)\n        return anomaly_scores, query_distances, query_nns\n", "docs": [{"text": "    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n\n    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "class RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        cloner.useFloat16 = True\n        return cloner\n\n    def _create_index(self, dimension):\n        index = faiss.IndexIVFPQ(\n            faiss.IndexFlatL2(dimension),\n            dimension,\n            512,  # n_centroids\n            64,  # sub-quantizers\n            8,\n        )  # nbits per code\n        return self._index_to_gpu(index)\n\n\nclass _BaseMerger:\n    def __init__(self):\n        \"\"\"Merges feature embedding by name.\"\"\"\n\n    def merge(self, features: list):\n        features = [self._reduce(feature) for feature in features]\n        return np.concatenate(features, axis=1)\n\n\nclass AverageMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxC\n        return features.reshape([features.shape[0], features.shape[1], -1]).mean(\n            axis=-1\n        )\n\n\nclass ConcatMerger(_BaseMerger):\n    @staticmethod\n    def _reduce(features):\n        # NxCxWxH -> NxCWH\n        return features.reshape(len(features), -1)\n\n\nclass Preprocessing(torch.nn.Module):\n    def __init__(self, input_dims, output_dim):\n        super(Preprocessing, self).__init__()\n        self.input_dims = input_dims\n        self.output_dim = output_dim\n\n        self.preprocessing_modules = torch.nn.ModuleList()\n        for input_dim in input_dims:\n            module = MeanMapper(output_dim)\n            self.preprocessing_modules.append(module)\n", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            feature_dimensions, pretrain_embed_dimension\n        )\n        self.forward_modules[\"preprocessing\"] = preprocessing\n\n        self.target_embed_dimension = target_embed_dimension\n        preadapt_aggregator = patchcore.common.Aggregator(\n            target_dim=target_embed_dimension\n        )\n\n        _ = preadapt_aggregator.to(self.device)\n\n        self.forward_modules[\"preadapt_aggregator\"] = preadapt_aggregator\n\n        self.anomaly_scorer = patchcore.common.NearestNeighbourScorer(\n            n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method\n        )\n\n        self.anomaly_segmentor = patchcore.common.RescaleSegmentor(\n            device=self.device, target_size=input_shape[-2:]\n        )\n\n        self.featuresampler = featuresampler\n\n    def embed(self, data):\n        if isinstance(data, torch.utils.data.DataLoader):\n            features = []\n            for image in data:\n                if isinstance(image, dict):\n                    image = image[\"image\"]\n                with torch.no_grad():\n                    input_image = image.to(torch.float).to(self.device)\n                    features.append(self._embed(input_image))\n            return features\n        return self._embed(data)\n\n    def _embed(self, images, detach=True, provide_patch_shapes=False):\n        \"\"\"Returns feature embeddings for images.\"\"\"\n\n        def _detach(features):\n            if detach:\n                return [x.detach().cpu().numpy() for x in features]\n            return features\n\n        _ = self.forward_modules[\"feature_aggregator\"].eval()\n        with torch.no_grad():\n            features = self.forward_modules[\"feature_aggregator\"](images)\n\n        features = [features[layer] for layer in self.layers_to_extract_from]\n\n        features = [", "title": "amazon-science_patchcore-inspection-src-patchcore-patchcore.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/30", "ground_truth": "        query_features = self.feature_merger.merge(\n            query_features,\n        )\n        query_distances, query_nns = self.imagelevel_nn(query_features)\n        anomaly_scores = np.mean(query_distances, axis=-1)\n        return anomaly_scores, query_distances, query_nns\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 152, "lineno": 344, "function_name": "predict"}}
{"prompt": "target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):\n        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n\n\nclass LastLayerToExtractReachedException(Exception):\n    pass\n\n\nclass NearestNeighbourScorer(object):\n    def __init__(self, n_nearest_neighbours: int, nn_method=FaissNN(False, 4)) -> None:\n        \"\"\"\n        Neearest-Neighbourhood Anomaly Scorer class.\n\n        Args:\n            n_nearest_neighbours: [int] Number of nearest neighbours used to\n                determine anomalous pixels.\n            nn_method: Nearest neighbour search method.\n        \"\"\"\n        self.feature_merger = ConcatMerger()\n\n        self.n_nearest_neighbours = n_nearest_neighbours\n        self.nn_method = nn_method\n\n        self.imagelevel_nn = lambda query: self.nn_method.run(\n            n_nearest_neighbours, query\n        )\n        self.pixelwise_nn = lambda query, index: self.nn_method.run(1, query, index)\n\n    def fit(self, detection_features: List[np.ndarray]) -> None:\n        \"\"\"Calls the fit function of the nearest neighbour method.\n\n        Args:\n            detection_features: [list of np.arrays]\n                [[bs x d_i] for i in n] Contains a list of\n                np.arrays for all training images corresponding to respective\n                features VECTORS (or maps, but will be resized) produced by\n                some backbone network which should be used for image-level\n                anomaly detection.\n        \"\"\"\n        self.detection_features = self.feature_merger.merge(\n            detection_features,\n        )\n        self.nn_method.fit(self.detection_features)\n\n    def predict(\n        self, query_features: List[np.ndarray]\n    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Predicts anomaly score.\n\n        Searches for nearest neighbours of test images in all\n        support training images.\n\n        Args:\n             detection_query_features: [dict of np.arrays] List of np.arrays\n                 corresponding to the test features generated by\n                 some backbone network.\n        \"\"\"\n        query_features = self.feature_merger.merge(\n            query_features,\n        )\n        query_distances, query_nns = self.imagelevel_nn(query_features)\n        anomaly_scores = np.mean(query_distances, axis=-1)\n        return anomaly_scores, query_distances, query_nns\n\n    @staticmethod\n    def _detection_file(folder, prepend=\"\"):\n        return os.path.join(folder, prepend + \"nnscorer_features.pkl\")\n\n    @staticmethod\n    def _index_file(folder, prepend=\"\"):\n        return os.path.join(folder, prepend + \"nnscorer_search_index.faiss\")\n\n    @staticmethod\n    def _save(filename, features):\n        if features is None:\n            return\n        with open(filename, \"wb\") as save_file:\n            pickle.dump(features, save_file, pickle.HIGHEST_PROTOCOL)\n\n    @staticmethod\n    def _load(filename: str):\n        with open(filename, \"rb\") as load_file:\n            return pickle.load(load_file)\n\n    def save(\n        self,\n        save_folder: str,\n        save_features_separately: bool = False,\n        prepend: str = \"\",\n    ) -> None:", "reference": "        self.nn_method.save(self._index_file(save_folder, prepend))\n        if save_features_separately:\n            self._save(\n                self._detection_file(save_folder, prepend), self.detection_features\n            )\n", "docs": [{"text": "class RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()\n        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [\n            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n            for patch_score in patch_scores\n        ]\n\n\nclass NetworkFeatureAggregator(torch.nn.Module):\n    \"\"\"Efficient extraction of network features.\"\"\"\n\n    def __init__(self, backbone, layers_to_extract_from, device):\n        super(NetworkFeatureAggregator, self).__init__()", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        \"\"\"Extraction of network features.\n\n        Runs a network only to the last layer of the list of layers where\n        network features should be extracted from.\n\n        Args:\n            backbone: torchvision.model\n            layers_to_extract_from: [list of str]\n        \"\"\"\n        self.layers_to_extract_from = layers_to_extract_from\n        self.backbone = backbone\n        self.device = device\n        if not hasattr(backbone, \"hook_handles\"):\n            self.backbone.hook_handles = []\n        for handle in self.backbone.hook_handles:\n            handle.remove()\n        self.outputs = {}\n\n        for extract_layer in layers_to_extract_from:\n            forward_hook = ForwardHook(\n                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "        layers_to_extract_from_coll = [[] for _ in range(len(backbone_names))]\n        for layer in layers_to_extract_from:\n            idx = int(layer.split(\".\")[0])\n            layer = \".\".join(layer.split(\".\")[1:])\n            layers_to_extract_from_coll[idx].append(layer)\n    else:\n        layers_to_extract_from_coll = [layers_to_extract_from]\n\n    def get_patchcore(input_shape, sampler, device):\n        loaded_patchcores = []\n        for backbone_name, layers_to_extract_from in zip(\n            backbone_names, layers_to_extract_from_coll\n        ):\n            backbone_seed = None\n            if \".seed-\" in backbone_name:\n                backbone_name, backbone_seed = backbone_name.split(\".seed-\")[0], int(\n                    backbone_name.split(\"-\")[-1]\n                )\n            backbone = patchcore.backbones.load(backbone_name)\n            backbone.name, backbone.seed = backbone_name, backbone_seed\n\n            nn_method = patchcore.common.FaissNN(faiss_on_gpu, faiss_num_workers)\n\n            patchcore_instance = patchcore.patchcore.PatchCore(device)\n            patchcore_instance.load(\n                backbone=backbone,\n                layers_to_extract_from=layers_to_extract_from,\n                device=device,\n                input_shape=input_shape,\n                pretrain_embed_dimension=pretrain_embed_dimension,\n                target_embed_dimension=target_embed_dimension,\n                patchsize=patchsize,\n                featuresampler=sampler,\n                anomaly_scorer_num_nn=anomaly_scorer_num_nn,\n                nn_method=nn_method,\n            )\n            loaded_patchcores.append(patchcore_instance)\n        return loaded_patchcores\n\n    return (\"get_patchcore\", get_patchcore)\n\n\n@main.command(\"sampler\")\n@click.argument(\"name\", type=str)\n@click.option(\"--percentage\", \"-p\", type=float, default=0.1, show_default=True)\ndef sampler(name, percentage):\n    def get_sampler(device):\n        if name == \"identity\":\n            return patchcore.sampler.IdentitySampler()\n        elif name == \"greedy_coreset\":", "title": "amazon-science_patchcore-inspection-bin-run_patchcore.py"}, {"text": "    def forward(self, features):\n        _features = []\n        for module, feature in zip(self.preprocessing_modules, features):\n            _features.append(module(feature))\n        return torch.stack(_features, dim=1)\n\n\nclass MeanMapper(torch.nn.Module):\n    def __init__(self, preprocessing_dim):\n        super(MeanMapper, self).__init__()\n        self.preprocessing_dim = preprocessing_dim\n\n    def forward(self, features):\n        features = features.reshape(len(features), 1, -1)\n        return F.adaptive_avg_pool1d(features, self.preprocessing_dim).squeeze(1)\n\n\nclass Aggregator(torch.nn.Module):\n    def __init__(self, target_dim):\n        super(Aggregator, self).__init__()\n        self.target_dim = target_dim\n\n    def forward(self, features):\n        \"\"\"Returns reshaped and average pooled features.\"\"\"\n        # batchsize x number_of_layers x input_dim -> batchsize x target_dim\n        features = features.reshape(len(features), 1, -1)\n        features = F.adaptive_avg_pool1d(features, self.target_dim)\n        return features.reshape(len(features), -1)\n\n\nclass RescaleSegmentor:\n    def __init__(self, device, target_size=224):\n        self.device = device\n        self.target_size = target_size\n        self.smoothing = 4\n\n    def convert_to_segmentation(self, patch_scores):\n\n        with torch.no_grad():\n            if isinstance(patch_scores, np.ndarray):\n                patch_scores = torch.from_numpy(patch_scores)\n            _scores = patch_scores.to(self.device)\n            _scores = _scores.unsqueeze(1)\n            _scores = F.interpolate(\n                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n            )\n            _scores = _scores.squeeze(1)\n            patch_scores = _scores.cpu().numpy()\n\n        return [", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):\n        self.hook_dict[self.layer_name] = output\n        if self.raise_exception_to_break:\n            raise LastLayerToExtractReachedException()\n        return None\n\n\nclass LastLayerToExtractReachedException(Exception):\n    pass\n\n\nclass NearestNeighbourScorer(object):\n    def __init__(self, n_nearest_neighbours: int, nn_method=FaissNN(False, 4)) -> None:\n        \"\"\"\n        Neearest-Neighbourhood Anomaly Scorer class.\n\n        Args:\n            n_nearest_neighbours: [int] Number of nearest neighbours used to\n                determine anomalous pixels.\n            nn_method: Nearest neighbour search method.\n        \"\"\"", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}, {"text": "                self.outputs, extract_layer, layers_to_extract_from[-1]\n            )\n            if \".\" in extract_layer:\n                extract_block, extract_idx = extract_layer.split(\".\")\n                network_layer = backbone.__dict__[\"_modules\"][extract_block]\n                if extract_idx.isnumeric():\n                    extract_idx = int(extract_idx)\n                    network_layer = network_layer[extract_idx]\n                else:\n                    network_layer = network_layer.__dict__[\"_modules\"][extract_idx]\n            else:\n                network_layer = backbone.__dict__[\"_modules\"][extract_layer]\n\n            if isinstance(network_layer, torch.nn.Sequential):\n                self.backbone.hook_handles.append(\n                    network_layer[-1].register_forward_hook(forward_hook)\n                )\n            else:\n                self.backbone.hook_handles.append(\n                    network_layer.register_forward_hook(forward_hook)\n                )\n        self.to(self.device)\n\n    def forward(self, images):\n        self.outputs.clear()\n        with torch.no_grad():\n            # The backbone will throw an Exception once it reached the last\n            # layer to compute features from. Computation will stop there.\n            try:\n                _ = self.backbone(images)\n            except LastLayerToExtractReachedException:\n                pass\n        return self.outputs\n\n    def feature_dimensions(self, input_shape):\n        \"\"\"Computes the feature dimensions for all layers given input_shape.\"\"\"\n        _input = torch.ones([1] + list(input_shape)).to(self.device)\n        _output = self(_input)\n        return [_output[layer].shape[1] for layer in self.layers_to_extract_from]\n\n\nclass ForwardHook:\n    def __init__(self, hook_dict, layer_name: str, last_layer_to_extract: str):\n        self.hook_dict = hook_dict\n        self.layer_name = layer_name\n        self.raise_exception_to_break = copy.deepcopy(\n            layer_name == last_layer_to_extract\n        )\n\n    def __call__(self, module, input, output):", "title": "amazon-science_patchcore-inspection-src-patchcore-common.py"}], "metadata": {"task_id": "amazon-science_patchcore-inspection/31", "ground_truth": "        self.nn_method.save(self._index_file(save_folder, prepend))\n        if save_features_separately:\n            self._save(\n                self._detection_file(save_folder, prepend), self.detection_features\n            )\n", "fpath_tuple": ["amazon-science_patchcore-inspection", "src", "patchcore", "common.py"], "context_start_lineno": 181, "lineno": 377, "function_name": "save"}}
